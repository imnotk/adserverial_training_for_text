0it [00:00, ?it/s]4621it [00:00, 46208.72it/s]9248it [00:00, 46225.22it/s]13821it [00:00, 46073.75it/s]18462it [00:00, 46172.84it/s]23137it [00:00, 46344.08it/s]27815it [00:00, 46472.92it/s]32480it [00:00, 46523.79it/s]36753it [00:00, 35580.82it/s]41432it [00:00, 38335.33it/s]46140it [00:01, 40595.94it/s]50832it [00:01, 42306.49it/s]55524it [00:01, 43590.63it/s]60160it [00:01, 44384.86it/s]64874it [00:01, 45174.67it/s]69553it [00:01, 45645.83it/s]74237it [00:01, 45995.13it/s]78906it [00:01, 46199.13it/s]83545it [00:01, 34681.39it/s]88240it [00:02, 37630.63it/s]92945it [00:02, 40033.43it/s]97644it [00:02, 41892.94it/s]102348it [00:02, 43312.22it/s]106989it [00:02, 44196.80it/s]111689it [00:02, 45001.07it/s]116413it [00:02, 45649.15it/s]121141it [00:02, 46124.97it/s]125870it [00:02, 46468.35it/s]130552it [00:03, 33054.78it/s]135254it [00:03, 36287.14it/s]139933it [00:03, 38905.35it/s]144606it [00:03, 40961.78it/s]149215it [00:03, 42376.12it/s]153855it [00:03, 43507.54it/s]158520it [00:03, 44404.16it/s]163201it [00:03, 45097.44it/s]167870it [00:03, 45561.34it/s]172576it [00:04, 45999.67it/s]177299it [00:04, 46360.05it/s]180000it [00:04, 42930.99it/s]
0it [00:00, ?it/s]4664it [00:00, 46639.93it/s]7093it [00:00, 24183.36it/s]10000it [00:00, 26599.06it/s]
0it [00:00, ?it/s]4636it [00:00, 46353.41it/s]9245it [00:00, 46273.69it/s]10000it [00:00, 46055.42it/s]
Loading data...
Vocab size: 4762
Time usage: 0:00:05
<bound method Module.parameters of Model(
  (embedding): Embedding(4762, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 256, kernel_size=(2, 300), stride=(1, 1))
    (1): Conv2d(1, 256, kernel_size=(3, 300), stride=(1, 1))
    (2): Conv2d(1, 256, kernel_size=(4, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=768, out_features=10, bias=True)
)>
Epoch [1/20]
Iter:      0,  Train Loss:   2.3,  Train Acc:  8.59%,  Val Loss:   2.7,  Val Acc: 10.00%,  Time: 0:00:01 *
Iter:    100,  Train Loss:  0.73,  Train Acc: 76.56%,  Val Loss:   0.7,  Val Acc: 78.19%,  Time: 0:00:04 *
Iter:    200,  Train Loss:   0.7,  Train Acc: 72.66%,  Val Loss:  0.55,  Val Acc: 83.27%,  Time: 0:00:07 *
Iter:    300,  Train Loss:  0.52,  Train Acc: 85.16%,  Val Loss:  0.49,  Val Acc: 84.71%,  Time: 0:00:10 *
Iter:    400,  Train Loss:   0.7,  Train Acc: 78.12%,  Val Loss:  0.48,  Val Acc: 85.37%,  Time: 0:00:13 *
Iter:    500,  Train Loss:  0.38,  Train Acc: 89.06%,  Val Loss:  0.44,  Val Acc: 86.28%,  Time: 0:00:16 *
Iter:    600,  Train Loss:  0.53,  Train Acc: 84.38%,  Val Loss:  0.42,  Val Acc: 86.70%,  Time: 0:00:19 *
Iter:    700,  Train Loss:  0.45,  Train Acc: 79.69%,  Val Loss:   0.4,  Val Acc: 87.30%,  Time: 0:00:23 *
Iter:    800,  Train Loss:  0.49,  Train Acc: 85.16%,  Val Loss:  0.39,  Val Acc: 87.82%,  Time: 0:00:26 *
Iter:    900,  Train Loss:  0.42,  Train Acc: 89.84%,  Val Loss:  0.39,  Val Acc: 88.09%,  Time: 0:00:28 *
Iter:   1000,  Train Loss:  0.34,  Train Acc: 90.62%,  Val Loss:  0.39,  Val Acc: 87.77%,  Time: 0:00:31 
Iter:   1100,  Train Loss:  0.42,  Train Acc: 88.28%,  Val Loss:  0.38,  Val Acc: 88.26%,  Time: 0:00:34 *
Iter:   1200,  Train Loss:  0.39,  Train Acc: 86.72%,  Val Loss:  0.37,  Val Acc: 88.88%,  Time: 0:00:37 *
Iter:   1300,  Train Loss:  0.42,  Train Acc: 85.16%,  Val Loss:  0.37,  Val Acc: 88.66%,  Time: 0:00:40 
Iter:   1400,  Train Loss:  0.49,  Train Acc: 85.16%,  Val Loss:  0.36,  Val Acc: 88.95%,  Time: 0:00:43 *
Epoch [2/20]
Iter:   1500,  Train Loss:  0.34,  Train Acc: 90.62%,  Val Loss:  0.36,  Val Acc: 88.95%,  Time: 0:00:46 *
Iter:   1600,  Train Loss:  0.29,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 88.92%,  Time: 0:00:49 *
Iter:   1700,  Train Loss:  0.35,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 89.48%,  Time: 0:00:52 *
Iter:   1800,  Train Loss:  0.33,  Train Acc: 90.62%,  Val Loss:  0.36,  Val Acc: 88.84%,  Time: 0:00:55 
Iter:   1900,  Train Loss:  0.32,  Train Acc: 87.50%,  Val Loss:  0.34,  Val Acc: 89.47%,  Time: 0:00:58 *
Iter:   2000,  Train Loss:  0.38,  Train Acc: 85.16%,  Val Loss:  0.34,  Val Acc: 89.33%,  Time: 0:01:01 
Iter:   2100,  Train Loss:  0.38,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 89.34%,  Time: 0:01:04 
Iter:   2200,  Train Loss:  0.34,  Train Acc: 89.06%,  Val Loss:  0.34,  Val Acc: 89.41%,  Time: 0:01:07 
Iter:   2300,  Train Loss:  0.38,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 89.46%,  Time: 0:01:10 *
Iter:   2400,  Train Loss:  0.22,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 89.85%,  Time: 0:01:13 *
Iter:   2500,  Train Loss:   0.2,  Train Acc: 94.53%,  Val Loss:  0.33,  Val Acc: 89.89%,  Time: 0:01:16 *
Iter:   2600,  Train Loss:  0.41,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 89.85%,  Time: 0:01:19 
Iter:   2700,  Train Loss:  0.27,  Train Acc: 89.06%,  Val Loss:  0.34,  Val Acc: 89.49%,  Time: 0:01:22 
Iter:   2800,  Train Loss:  0.34,  Train Acc: 86.72%,  Val Loss:  0.34,  Val Acc: 89.68%,  Time: 0:01:25 
Epoch [3/20]
Iter:   2900,  Train Loss:  0.39,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 89.69%,  Time: 0:01:28 *
Iter:   3000,  Train Loss:  0.31,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.84%,  Time: 0:01:31 
Iter:   3100,  Train Loss:  0.25,  Train Acc: 92.19%,  Val Loss:  0.34,  Val Acc: 89.45%,  Time: 0:01:34 
Iter:   3200,  Train Loss:  0.36,  Train Acc: 89.06%,  Val Loss:  0.34,  Val Acc: 89.70%,  Time: 0:01:37 
Iter:   3300,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 90.05%,  Time: 0:01:40 
Iter:   3400,  Train Loss:  0.28,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 90.22%,  Time: 0:01:43 
Iter:   3500,  Train Loss:  0.18,  Train Acc: 95.31%,  Val Loss:  0.33,  Val Acc: 89.81%,  Time: 0:01:46 
Iter:   3600,  Train Loss:  0.16,  Train Acc: 94.53%,  Val Loss:  0.33,  Val Acc: 90.03%,  Time: 0:01:49 
Iter:   3700,  Train Loss:  0.29,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 89.85%,  Time: 0:01:52 
Iter:   3800,  Train Loss:  0.33,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 90.11%,  Time: 0:01:55 
Iter:   3900,  Train Loss:  0.31,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 89.90%,  Time: 0:01:57 
No optimization for a long time, auto-stopping...
Test Loss:   0.3,  Test Acc: 90.45%
Precision, Recall and F1-Score...
               precision    recall  f1-score   support

      finance     0.9409    0.8600    0.8986      1000
       realty     0.9183    0.9220    0.9202      1000
       stocks     0.8476    0.8620    0.8547      1000
    education     0.9519    0.9490    0.9504      1000
      science     0.8473    0.8710    0.8590      1000
      society     0.8726    0.9250    0.8981      1000
     politics     0.8959    0.8860    0.8909      1000
       sports     0.9485    0.9570    0.9527      1000
         game     0.9106    0.9070    0.9088      1000
entertainment     0.9189    0.9060    0.9124      1000

     accuracy                         0.9045     10000
    macro avg     0.9052    0.9045    0.9046     10000
 weighted avg     0.9052    0.9045    0.9046     10000

Confusion Matrix...
[[860  21  70   4  14  11  10   5   4   1]
 [  9 922  16   2  10  17   8   5   2   9]
 [ 34  21 862   3  34   3  30   2   9   2]
 [  0   2   3 949   3  17   8   5   2  11]
 [  0   6  33   6 871  17  18   4  34  11]
 [  3  19   0  15   9 925  16   1   3   9]
 [  6   5  24   6  19  39 886   3   2  10]
 [  0   1   1   1   6  11   5 957   2  16]
 [  1   2   7   3  47   8   4  10 907  11]
 [  1   5   1   8  15  12   4  17  31 906]]
Time usage: 0:00:00
